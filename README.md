
# ğŸ“š Tech Challenge - API PÃºblica de Livros

Projeto desenvolvido para o Tech Challenge da PÃ³s-Tech, Fase 1, com foco em Engenharia de Machine Learning.

O desafio propÃµe a criaÃ§Ã£o de um pipeline de dados com web scraping, transformaÃ§Ã£o e disponibilizaÃ§Ã£o dos dados de livros via API RESTful, com foco em **escalabilidade** e **reusabilidade** para futuros modelos de machine learning.

---

## ğŸ¯ Objetivo

- Criar um pipeline de dados completo.
- Disponibilizar os dados via API pÃºblica.
- Preparar a soluÃ§Ã£o para futuros usos em projetos de ML.
- Publicar a soluÃ§Ã£o em ambiente de produÃ§Ã£o com esteira CI/CD.

---
## ğŸ“Œ Premissas Atendidas

- Pipeline completo de dados
- API REST funcional
- Web scraping robusto
- Dados estruturados para ML
- Deploy pÃºblico disponÃ­vel


---
## ğŸ“Œ Tecnologias envoldidas

- Python - utilizado para criar o codigo do webscraping

- AWS - utilizado para automatizar o scraping via Lambda Function e armazenar os resultados em S3

- Snowflake - utilizado para integrar com o S3 e fazer a ingestÃ£o na tabela final do banco de dados de maneira estruturada

- Plataforma Render - utilizado para expor a API e rotas que irÃ£o consumir os dados do Snowflake



---

## ğŸ§© Arquitetura da SoluÃ§Ã£o

![Arquitetura da SoluÃ§Ã£o](Insumos/Arquitetura%20da%20soluÃ§Ã£o.jpg)

## ğŸš€ Processo de Deploy

![Fluxo de Deploy](Insumos/fluxo_de_deploy.jpg)


---

## ğŸ—‚ Estrutura do RepositÃ³rio

```
MLET_TC01/
â”œâ”€â”€ api/                  # ImplementaÃ§Ã£o da API (FastAPI)
â”œâ”€â”€ scripts/              # Script de Web Scraping (scraper.py)
â”œâ”€â”€ models/               # Modelos ORM com SQLAlchemy
â”œâ”€â”€ database/             # ConexÃ£o e setup do SQLite
â”œâ”€â”€ data/                 # Armazenamento local dos dados (.csv)
â”œâ”€â”€ ingest_data.py        # Script de ingestÃ£o de dados no banco
â”œâ”€â”€ requirements.txt      # DependÃªncias do projeto
â””â”€â”€ README.md             # Este arquivo
```


---

## ğŸ”— Endpoints da API

### Core
- `GET /api/v1/books` â€“ Lista todos os livros
- `GET /api/v1/books/{id}` â€“ Detalhes de um livro
- `GET /api/v1/books/search?title=&category=` â€“ Busca por tÃ­tulo e/ou categoria
- `GET /api/v1/categories` â€“ Lista de categorias
- `GET /api/v1/health` â€“ Verifica status da API

## ğŸ” AutenticaÃ§Ã£o com JWT

O projeto conta com autenticaÃ§Ã£o implementada usando **JWT (JSON Web Tokens)**.

### Rotas de autenticaÃ§Ã£o:

- `POST /api/v1/auth/login` â€“ Realiza o login e retorna um token JWT.
- `POST /api/v1/auth/refresh` â€“ Gera um novo token com base no token de refresh.

### Endpoints protegidos

- Endpoints sensÃ­veis como `/api/v1/scraping/trigger` estÃ£o protegidos e exigem um token vÃ¡lido.
- Para acessar esses endpoints, inclua o header:
```
Authorization: Bearer <seu_token>
```

Essa implementaÃ§Ã£o garante seguranÃ§a bÃ¡sica para administraÃ§Ã£o da API e controle de acesso Ã s operaÃ§Ãµes crÃ­ticas.

### Insights (opcional)
- `GET /api/v1/stats/overview` â€“ EstatÃ­sticas gerais
- `GET /api/v1/stats/categories` â€“ EstatÃ­sticas por categoria
- `GET /api/v1/books/top-rated` â€“ Melhores avaliaÃ§Ãµes
- `GET /api/v1/books/price-range?min=&max=` â€“ Faixa de preÃ§o

---

## ğŸ§© AWS

A plataforma AWS foi escolhida por fornecer engines escalÃ¡veis, facil gerenciamento e baixo custo para o nosso caso de uso

1. **IngestÃ£o:**

A ingestÃ£o Ã© realizada por uma lambda function que pode ser disparada manualmente ou via Schedule atraves do AWS Event Bridge(crontab)

A Lambda function realiza o scraping da informaÃ§Ãµes de livros do site https://books.toscrape.com/

![Lambda_1](Insumos/Lambda_screen1.png)
![Lambda_2](Insumos/Lambda_screen2.png)

2. **Armazenamento:**

O resultado da funÃ§Ã£o Lambda Ã© um arquivo csv no S3  

![s3csv](Insumos/S3CSV.png)


## ğŸ§© SNOWFLAKE

A plataforma de dados Snowflake foi escolhida por fornecer um ambiente de dados escalaveis para requisiÃ§Ãµes das apis, baixo esforÃ§o de construÃ§Ã£o do ambiente e de custo gratuito para o desenvolvimento desse trabalho.

1. **IngestÃ£o:**

A ingestÃ£o no snowflake Ã© realizada por uma feature chamada SNOWPIPE.

Essa feature tem por objetivo carregar dados de um S3, assim que receber um evento do mesmo, para uma tabela no Snowflake

2. **Armazenamento:**

A tabela no snowflake Ã© chamada TB_BOOKS_TO_SCRAPE e tem o seguinte formato estruturado abaixo

Essa tabela servira de base para o consumo de informaÃ§Ã£o das APIS

![books](Insumos/Tabela_books.png)

---

## ğŸ§© RENDER

A plataforma Render foi escolhida pelo time para realizar o deploy das APIs utilizando uma URL publica que permitindo que suas rotas sejam acessadas.

Essa plataforma foi escolhida em virtude do minimo esforÃ§o de deploy das APIs, visto que Ã© facilmente integravel com o GITHUB, e por possuir plano gratuito que Ã© suficiente para o caso de uso do nosso trabalho

As rotas e apis podem ser acessadas na url: ğŸ”— https://scrap-api-kwuu.onrender.com


![Render](Insumos/Render.png)

---
## ğŸ¥ ApresentaÃ§Ã£o

ğŸ”— https://www.youtube.com/watch?v=hgaGc_RikiQ

---
